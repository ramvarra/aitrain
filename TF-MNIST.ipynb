{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de95ea73-ec27-4365-8076-c7aaa62cd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe935a41-036a-4ab3-b51a-b84613f90d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.6.2\n",
      "Logical Devices: [LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "Physical Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 02:31:25.744659: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-13 02:31:25.744683: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-13 02:31:25.744698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5c6edf48fe91): /proc/driver/nvidia/version does not exist\n",
      "2022-02-13 02:31:25.744893: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "util.show_tf_info(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "822f1010-cdd5-475c-be72-19541dd18208",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NUM_CLASSES = 10 # number of digits 0..9\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = .2 # portion of train data reserved for validation\n",
    "DROP_OUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8032b7-7e99-44f2-be44-a2fae1bb60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats(name, v):\n",
    "    print(f\"{name}.shape: {v.shape} dtype: {v.dtype}, min: {v.min()}, max: {v.max()}, mean: {v.mean()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fe3258-e302-42aa-8830-a865a930894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n",
      "x_train.shape: (60000, 784) dtype: float32, min: 0.0, max: 1.0, mean: 0.13066062331199646\n",
      "x_test.shape: (10000, 784) dtype: float32, min: 0.0, max: 1.0, mean: 0.13251467049121857\n",
      "y_train.shape: (60000, 10) dtype: float32, min: 0.0, max: 1.0, mean: 0.10000000149011612\n",
      "y_test.shape: (10000, 10) dtype: float32, min: 0.0, max: 1.0, mean: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# reshape the X into 2D, convert to float32, normalize by dividing by 255 \n",
    "x_train, x_test = (x.reshape(x.shape[0], -1).astype(np.float32)/255 for x in (x_train, x_test))\n",
    "show_stats(\"x_train\", x_train)\n",
    "show_stats(\"x_test\", x_test)\n",
    "\n",
    "# One hot encode Y\n",
    "y_train, y_test = (tf.keras.utils.to_categorical(y, NUM_CLASSES) for y in (y_train, y_test))\n",
    "show_stats(\"y_train\", y_train)\n",
    "show_stats(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1eea37-46b6-473b-b7a5-605d4c092449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8b10269-f4de-4ad3-8876-313e84f63f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MNIST-2H\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_01 (Dense)      (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_02 (Dense)      (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_03 (Dense)      (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "ouput_layer (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential(name='MNIST-2H')\n",
    "for layer in [\n",
    "    tf.keras.layers.Dense(N_HIDDEN, name='hidden_layer_01', input_shape=(x_train.shape[1],),  activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROP_OUT),\n",
    "    tf.keras.layers.Dense(N_HIDDEN, name='hidden_layer_02', activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROP_OUT),\n",
    "    tf.keras.layers.Dense(N_HIDDEN, name='hidden_layer_03', activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROP_OUT),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, name='ouput_layer', activation='softmax'),\n",
    "]: model.add(layer)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b2af340-c200-4077-a18d-bf05035deecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0407 - accuracy: 0.3084 - val_loss: 1.3782 - val_accuracy: 0.7357\n",
      "Epoch 2/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.2518 - accuracy: 0.5947 - val_loss: 0.6445 - val_accuracy: 0.8514\n",
      "Epoch 3/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8645 - accuracy: 0.7202 - val_loss: 0.4710 - val_accuracy: 0.8756\n",
      "Epoch 4/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.7016 - accuracy: 0.7791 - val_loss: 0.3934 - val_accuracy: 0.8910\n",
      "Epoch 5/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6121 - accuracy: 0.8106 - val_loss: 0.3537 - val_accuracy: 0.9007\n",
      "Epoch 6/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.5546 - accuracy: 0.8306 - val_loss: 0.3247 - val_accuracy: 0.9078\n",
      "Epoch 7/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.8473 - val_loss: 0.3010 - val_accuracy: 0.9143\n",
      "Epoch 8/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.8576 - val_loss: 0.2816 - val_accuracy: 0.9181\n",
      "Epoch 9/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.4467 - accuracy: 0.8670 - val_loss: 0.2662 - val_accuracy: 0.9222\n",
      "Epoch 10/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.8771 - val_loss: 0.2548 - val_accuracy: 0.9246\n",
      "Epoch 11/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8805 - val_loss: 0.2429 - val_accuracy: 0.9290\n",
      "Epoch 12/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3836 - accuracy: 0.8864 - val_loss: 0.2328 - val_accuracy: 0.9309\n",
      "Epoch 13/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3682 - accuracy: 0.8937 - val_loss: 0.2246 - val_accuracy: 0.9327\n",
      "Epoch 14/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3603 - accuracy: 0.8961 - val_loss: 0.2181 - val_accuracy: 0.9352\n",
      "Epoch 15/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.9010 - val_loss: 0.2082 - val_accuracy: 0.9375\n",
      "Epoch 16/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.9047 - val_loss: 0.2017 - val_accuracy: 0.9401\n",
      "Epoch 17/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3208 - accuracy: 0.9063 - val_loss: 0.1969 - val_accuracy: 0.9414\n",
      "Epoch 18/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3100 - accuracy: 0.9100 - val_loss: 0.1897 - val_accuracy: 0.9442\n",
      "Epoch 19/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.9130 - val_loss: 0.1843 - val_accuracy: 0.9457\n",
      "Epoch 20/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2900 - accuracy: 0.9159 - val_loss: 0.1796 - val_accuracy: 0.9471\n",
      "Epoch 21/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2885 - accuracy: 0.9165 - val_loss: 0.1757 - val_accuracy: 0.9490\n",
      "Epoch 22/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2768 - accuracy: 0.9207 - val_loss: 0.1713 - val_accuracy: 0.9504\n",
      "Epoch 23/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2696 - accuracy: 0.9220 - val_loss: 0.1674 - val_accuracy: 0.9513\n",
      "Epoch 24/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2632 - accuracy: 0.9244 - val_loss: 0.1645 - val_accuracy: 0.9517\n",
      "Epoch 25/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2584 - accuracy: 0.9259 - val_loss: 0.1609 - val_accuracy: 0.9528\n",
      "Epoch 26/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.9276 - val_loss: 0.1571 - val_accuracy: 0.9539\n",
      "Epoch 27/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.9266 - val_loss: 0.1543 - val_accuracy: 0.9546\n",
      "Epoch 28/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.9302 - val_loss: 0.1527 - val_accuracy: 0.9548\n",
      "Epoch 29/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2372 - accuracy: 0.9309 - val_loss: 0.1503 - val_accuracy: 0.9553\n",
      "Epoch 30/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9319 - val_loss: 0.1490 - val_accuracy: 0.9554\n",
      "Epoch 31/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2289 - accuracy: 0.9337 - val_loss: 0.1463 - val_accuracy: 0.9577\n",
      "Epoch 32/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2275 - accuracy: 0.9336 - val_loss: 0.1444 - val_accuracy: 0.9581\n",
      "Epoch 33/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2237 - accuracy: 0.9346 - val_loss: 0.1424 - val_accuracy: 0.9588\n",
      "Epoch 34/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2142 - accuracy: 0.9379 - val_loss: 0.1385 - val_accuracy: 0.9603\n",
      "Epoch 35/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9385 - val_loss: 0.1377 - val_accuracy: 0.9601\n",
      "Epoch 36/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2120 - accuracy: 0.9380 - val_loss: 0.1364 - val_accuracy: 0.9601\n",
      "Epoch 37/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2070 - accuracy: 0.9402 - val_loss: 0.1329 - val_accuracy: 0.9613\n",
      "Epoch 38/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1997 - accuracy: 0.9422 - val_loss: 0.1317 - val_accuracy: 0.9609\n",
      "Epoch 39/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1954 - accuracy: 0.9429 - val_loss: 0.1309 - val_accuracy: 0.9617\n",
      "Epoch 40/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9438 - val_loss: 0.1299 - val_accuracy: 0.9622\n",
      "Epoch 41/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1955 - accuracy: 0.9424 - val_loss: 0.1275 - val_accuracy: 0.9627\n",
      "Epoch 42/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9442 - val_loss: 0.1274 - val_accuracy: 0.9622\n",
      "Epoch 43/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.9466 - val_loss: 0.1263 - val_accuracy: 0.9626\n",
      "Epoch 44/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.9466 - val_loss: 0.1243 - val_accuracy: 0.9628\n",
      "Epoch 45/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.9465 - val_loss: 0.1234 - val_accuracy: 0.9632\n",
      "Epoch 46/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9475 - val_loss: 0.1223 - val_accuracy: 0.9638\n",
      "Epoch 47/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9470 - val_loss: 0.1215 - val_accuracy: 0.9645\n",
      "Epoch 48/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1755 - accuracy: 0.9482 - val_loss: 0.1202 - val_accuracy: 0.9640\n",
      "Epoch 49/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1735 - accuracy: 0.9491 - val_loss: 0.1193 - val_accuracy: 0.9655\n",
      "Epoch 50/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1745 - accuracy: 0.9503 - val_loss: 0.1179 - val_accuracy: 0.9647\n",
      "Epoch 51/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1727 - accuracy: 0.9505 - val_loss: 0.1172 - val_accuracy: 0.9657\n",
      "Epoch 52/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1642 - accuracy: 0.9516 - val_loss: 0.1160 - val_accuracy: 0.9660\n",
      "Epoch 53/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.9500 - val_loss: 0.1148 - val_accuracy: 0.9663\n",
      "Epoch 54/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1649 - accuracy: 0.9517 - val_loss: 0.1129 - val_accuracy: 0.9668\n",
      "Epoch 55/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1629 - accuracy: 0.9523 - val_loss: 0.1134 - val_accuracy: 0.9663\n",
      "Epoch 56/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1609 - accuracy: 0.9531 - val_loss: 0.1128 - val_accuracy: 0.9672\n",
      "Epoch 57/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1593 - accuracy: 0.9534 - val_loss: 0.1121 - val_accuracy: 0.9675\n",
      "Epoch 58/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1562 - accuracy: 0.9547 - val_loss: 0.1116 - val_accuracy: 0.9672\n",
      "Epoch 59/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1518 - accuracy: 0.9561 - val_loss: 0.1116 - val_accuracy: 0.9673\n",
      "Epoch 60/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1511 - accuracy: 0.9556 - val_loss: 0.1101 - val_accuracy: 0.9683\n",
      "Epoch 61/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9561 - val_loss: 0.1097 - val_accuracy: 0.9678\n",
      "Epoch 62/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9559 - val_loss: 0.1087 - val_accuracy: 0.9676\n",
      "Epoch 63/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1467 - accuracy: 0.9574 - val_loss: 0.1088 - val_accuracy: 0.9678\n",
      "Epoch 64/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1463 - accuracy: 0.9573 - val_loss: 0.1083 - val_accuracy: 0.9683\n",
      "Epoch 65/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9555 - val_loss: 0.1076 - val_accuracy: 0.9688\n",
      "Epoch 66/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.9584 - val_loss: 0.1064 - val_accuracy: 0.9692\n",
      "Epoch 67/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1454 - accuracy: 0.9569 - val_loss: 0.1051 - val_accuracy: 0.9698\n",
      "Epoch 68/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1406 - accuracy: 0.9587 - val_loss: 0.1058 - val_accuracy: 0.9687\n",
      "Epoch 69/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9587 - val_loss: 0.1058 - val_accuracy: 0.9690\n",
      "Epoch 70/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1362 - accuracy: 0.9596 - val_loss: 0.1054 - val_accuracy: 0.9693\n",
      "Epoch 71/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9594 - val_loss: 0.1047 - val_accuracy: 0.9693\n",
      "Epoch 72/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9590 - val_loss: 0.1040 - val_accuracy: 0.9702\n",
      "Epoch 73/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1344 - accuracy: 0.9600 - val_loss: 0.1044 - val_accuracy: 0.9690\n",
      "Epoch 74/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.9599 - val_loss: 0.1035 - val_accuracy: 0.9707\n",
      "Epoch 75/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1344 - accuracy: 0.9602 - val_loss: 0.1020 - val_accuracy: 0.9703\n",
      "Epoch 76/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9621 - val_loss: 0.1030 - val_accuracy: 0.9698\n",
      "Epoch 77/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9617 - val_loss: 0.1024 - val_accuracy: 0.9699\n",
      "Epoch 78/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9622 - val_loss: 0.1041 - val_accuracy: 0.9697\n",
      "Epoch 79/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1292 - accuracy: 0.9618 - val_loss: 0.1017 - val_accuracy: 0.9703\n",
      "Epoch 80/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1272 - accuracy: 0.9617 - val_loss: 0.1013 - val_accuracy: 0.9707\n",
      "Epoch 81/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1254 - accuracy: 0.9616 - val_loss: 0.1013 - val_accuracy: 0.9703\n",
      "Epoch 82/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1231 - accuracy: 0.9630 - val_loss: 0.1014 - val_accuracy: 0.9706\n",
      "Epoch 83/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1216 - accuracy: 0.9638 - val_loss: 0.1006 - val_accuracy: 0.9713\n",
      "Epoch 84/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1205 - accuracy: 0.9645 - val_loss: 0.0996 - val_accuracy: 0.9715\n",
      "Epoch 85/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9638 - val_loss: 0.0992 - val_accuracy: 0.9716\n",
      "Epoch 86/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.9634 - val_loss: 0.0993 - val_accuracy: 0.9711\n",
      "Epoch 87/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.9639 - val_loss: 0.0981 - val_accuracy: 0.9718\n",
      "Epoch 88/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1193 - accuracy: 0.9650 - val_loss: 0.0979 - val_accuracy: 0.9722\n",
      "Epoch 89/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9662 - val_loss: 0.0989 - val_accuracy: 0.9718\n",
      "Epoch 90/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9647 - val_loss: 0.0992 - val_accuracy: 0.9718\n",
      "Epoch 91/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9663 - val_loss: 0.1003 - val_accuracy: 0.9721\n",
      "Epoch 92/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1146 - accuracy: 0.9668 - val_loss: 0.0974 - val_accuracy: 0.9721\n",
      "Epoch 93/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9656 - val_loss: 0.0980 - val_accuracy: 0.9721\n",
      "Epoch 94/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1127 - accuracy: 0.9666 - val_loss: 0.0989 - val_accuracy: 0.9712\n",
      "Epoch 95/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9671 - val_loss: 0.0983 - val_accuracy: 0.9724\n",
      "Epoch 96/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.0974 - val_accuracy: 0.9718\n",
      "Epoch 97/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1110 - accuracy: 0.9664 - val_loss: 0.0974 - val_accuracy: 0.9716\n",
      "Epoch 98/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1079 - accuracy: 0.9675 - val_loss: 0.0966 - val_accuracy: 0.9718\n",
      "Epoch 99/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.9679 - val_loss: 0.0968 - val_accuracy: 0.9723\n",
      "Epoch 100/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9687 - val_loss: 0.0969 - val_accuracy: 0.9712\n",
      "Epoch 101/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9683 - val_loss: 0.0972 - val_accuracy: 0.9724\n",
      "Epoch 102/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.9680 - val_loss: 0.0963 - val_accuracy: 0.9729\n",
      "Epoch 103/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.9687 - val_loss: 0.0953 - val_accuracy: 0.9731\n",
      "Epoch 104/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9692 - val_loss: 0.0954 - val_accuracy: 0.9731\n",
      "Epoch 105/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9688 - val_loss: 0.0953 - val_accuracy: 0.9728\n",
      "Epoch 106/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.9682 - val_loss: 0.0945 - val_accuracy: 0.9732\n",
      "Epoch 107/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.9690 - val_loss: 0.0948 - val_accuracy: 0.9734\n",
      "Epoch 108/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9701 - val_loss: 0.0946 - val_accuracy: 0.9732\n",
      "Epoch 109/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.9689 - val_loss: 0.0940 - val_accuracy: 0.9733\n",
      "Epoch 110/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9700 - val_loss: 0.0940 - val_accuracy: 0.9733\n",
      "Epoch 111/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.9704 - val_loss: 0.0948 - val_accuracy: 0.9732\n",
      "Epoch 112/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1007 - accuracy: 0.9696 - val_loss: 0.0943 - val_accuracy: 0.9730\n",
      "Epoch 113/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9708 - val_loss: 0.0938 - val_accuracy: 0.9728\n",
      "Epoch 114/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.0940 - val_accuracy: 0.9728\n",
      "Epoch 115/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9714 - val_loss: 0.0932 - val_accuracy: 0.9740\n",
      "Epoch 116/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9701 - val_loss: 0.0926 - val_accuracy: 0.9738\n",
      "Epoch 117/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0966 - accuracy: 0.9705 - val_loss: 0.0917 - val_accuracy: 0.9747\n",
      "Epoch 118/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0934 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9738\n",
      "Epoch 119/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9709 - val_loss: 0.0921 - val_accuracy: 0.9744\n",
      "Epoch 120/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0950 - accuracy: 0.9719 - val_loss: 0.0917 - val_accuracy: 0.9740\n",
      "Epoch 121/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9711 - val_loss: 0.0922 - val_accuracy: 0.9744\n",
      "Epoch 122/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9717 - val_loss: 0.0927 - val_accuracy: 0.9738\n",
      "Epoch 123/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0915 - accuracy: 0.9721 - val_loss: 0.0928 - val_accuracy: 0.9739\n",
      "Epoch 124/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9731 - val_loss: 0.0919 - val_accuracy: 0.9741\n",
      "Epoch 125/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9720 - val_loss: 0.0915 - val_accuracy: 0.9744\n",
      "Epoch 126/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9728 - val_loss: 0.0923 - val_accuracy: 0.9746\n",
      "Epoch 127/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9726 - val_loss: 0.0912 - val_accuracy: 0.9741\n",
      "Epoch 128/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9730 - val_loss: 0.0906 - val_accuracy: 0.9744\n",
      "Epoch 129/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9731 - val_loss: 0.0912 - val_accuracy: 0.9744\n",
      "Epoch 130/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9743 - val_loss: 0.0912 - val_accuracy: 0.9746\n",
      "Epoch 131/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9729 - val_loss: 0.0914 - val_accuracy: 0.9746\n",
      "Epoch 132/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9732 - val_loss: 0.0907 - val_accuracy: 0.9744\n",
      "Epoch 133/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9728 - val_loss: 0.0914 - val_accuracy: 0.9740\n",
      "Epoch 134/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.9736 - val_loss: 0.0910 - val_accuracy: 0.9744\n",
      "Epoch 135/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0817 - accuracy: 0.9749 - val_loss: 0.0913 - val_accuracy: 0.9745\n",
      "Epoch 136/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0838 - accuracy: 0.9743 - val_loss: 0.0906 - val_accuracy: 0.9743\n",
      "Epoch 137/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9741 - val_loss: 0.0917 - val_accuracy: 0.9741\n",
      "Epoch 138/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9743 - val_loss: 0.0919 - val_accuracy: 0.9741\n",
      "Epoch 139/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0846 - accuracy: 0.9739 - val_loss: 0.0901 - val_accuracy: 0.9747\n",
      "Epoch 140/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9746 - val_loss: 0.0916 - val_accuracy: 0.9745\n",
      "Epoch 141/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9754 - val_loss: 0.0910 - val_accuracy: 0.9750\n",
      "Epoch 142/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 0.0909 - val_accuracy: 0.9752\n",
      "Epoch 143/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0828 - accuracy: 0.9753 - val_loss: 0.0896 - val_accuracy: 0.9744\n",
      "Epoch 144/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0823 - accuracy: 0.9755 - val_loss: 0.0903 - val_accuracy: 0.9758\n",
      "Epoch 145/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0825 - accuracy: 0.9753 - val_loss: 0.0910 - val_accuracy: 0.9752\n",
      "Epoch 146/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9757 - val_loss: 0.0896 - val_accuracy: 0.9757\n",
      "Epoch 147/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0826 - accuracy: 0.9751 - val_loss: 0.0903 - val_accuracy: 0.9756\n",
      "Epoch 148/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0816 - accuracy: 0.9754 - val_loss: 0.0886 - val_accuracy: 0.9759\n",
      "Epoch 149/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9748 - val_loss: 0.0890 - val_accuracy: 0.9750\n",
      "Epoch 150/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9761 - val_loss: 0.0886 - val_accuracy: 0.9752\n",
      "Epoch 151/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0895 - val_accuracy: 0.9756\n",
      "Epoch 152/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9756 - val_loss: 0.0891 - val_accuracy: 0.9760\n",
      "Epoch 153/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0801 - accuracy: 0.9760 - val_loss: 0.0890 - val_accuracy: 0.9750\n",
      "Epoch 154/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0781 - accuracy: 0.9763 - val_loss: 0.0895 - val_accuracy: 0.9755\n",
      "Epoch 155/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0788 - accuracy: 0.9756 - val_loss: 0.0896 - val_accuracy: 0.9753\n",
      "Epoch 156/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0752 - accuracy: 0.9771 - val_loss: 0.0898 - val_accuracy: 0.9746\n",
      "Epoch 157/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0755 - accuracy: 0.9773 - val_loss: 0.0904 - val_accuracy: 0.9746\n",
      "Epoch 158/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0753 - accuracy: 0.9768 - val_loss: 0.0905 - val_accuracy: 0.9751\n",
      "Epoch 159/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9768 - val_loss: 0.0904 - val_accuracy: 0.9757\n",
      "Epoch 160/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9765 - val_loss: 0.0896 - val_accuracy: 0.9758\n",
      "Epoch 161/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9771 - val_loss: 0.0900 - val_accuracy: 0.9756\n",
      "Epoch 162/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9773 - val_loss: 0.0890 - val_accuracy: 0.9762\n",
      "Epoch 163/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9770 - val_loss: 0.0890 - val_accuracy: 0.9753\n",
      "Epoch 164/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9778 - val_loss: 0.0893 - val_accuracy: 0.9758\n",
      "Epoch 165/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9772 - val_loss: 0.0889 - val_accuracy: 0.9761\n",
      "Epoch 166/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9765 - val_loss: 0.0892 - val_accuracy: 0.9756\n",
      "Epoch 167/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0753 - accuracy: 0.9768 - val_loss: 0.0888 - val_accuracy: 0.9758\n",
      "Epoch 168/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0726 - accuracy: 0.9783 - val_loss: 0.0892 - val_accuracy: 0.9749\n",
      "Epoch 169/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: 0.0893 - val_accuracy: 0.9758\n",
      "Epoch 170/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0717 - accuracy: 0.9774 - val_loss: 0.0893 - val_accuracy: 0.9753\n",
      "Epoch 171/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0728 - accuracy: 0.9776 - val_loss: 0.0879 - val_accuracy: 0.9758\n",
      "Epoch 172/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0723 - accuracy: 0.9778 - val_loss: 0.0897 - val_accuracy: 0.9759\n",
      "Epoch 173/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0709 - accuracy: 0.9782 - val_loss: 0.0890 - val_accuracy: 0.9757\n",
      "Epoch 174/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0693 - accuracy: 0.9790 - val_loss: 0.0882 - val_accuracy: 0.9762\n",
      "Epoch 175/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0695 - accuracy: 0.9782 - val_loss: 0.0880 - val_accuracy: 0.9758\n",
      "Epoch 176/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0705 - accuracy: 0.9783 - val_loss: 0.0884 - val_accuracy: 0.9758\n",
      "Epoch 177/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9788 - val_loss: 0.0887 - val_accuracy: 0.9759\n",
      "Epoch 178/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9797 - val_loss: 0.0885 - val_accuracy: 0.9771\n",
      "Epoch 179/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9790 - val_loss: 0.0873 - val_accuracy: 0.9763\n",
      "Epoch 180/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9788 - val_loss: 0.0887 - val_accuracy: 0.9768\n",
      "Epoch 181/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 0.0890 - val_accuracy: 0.9759\n",
      "Epoch 182/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0696 - accuracy: 0.9784 - val_loss: 0.0885 - val_accuracy: 0.9766\n",
      "Epoch 183/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 0.0873 - val_accuracy: 0.9768\n",
      "Epoch 184/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9790 - val_loss: 0.0890 - val_accuracy: 0.9768\n",
      "Epoch 185/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.9790 - val_loss: 0.0894 - val_accuracy: 0.9764\n",
      "Epoch 186/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.0893 - val_accuracy: 0.9762\n",
      "Epoch 187/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9794 - val_loss: 0.0884 - val_accuracy: 0.9771\n",
      "Epoch 188/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.0881 - val_accuracy: 0.9772\n",
      "Epoch 189/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9799 - val_loss: 0.0888 - val_accuracy: 0.9770\n",
      "Epoch 190/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0638 - accuracy: 0.9800 - val_loss: 0.0895 - val_accuracy: 0.9767\n",
      "Epoch 191/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0653 - accuracy: 0.9794 - val_loss: 0.0892 - val_accuracy: 0.9758\n",
      "Epoch 192/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 0.0879 - val_accuracy: 0.9768\n",
      "Epoch 193/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.0877 - val_accuracy: 0.9768\n",
      "Epoch 194/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0621 - accuracy: 0.9804 - val_loss: 0.0897 - val_accuracy: 0.9760\n",
      "Epoch 195/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0642 - accuracy: 0.9796 - val_loss: 0.0878 - val_accuracy: 0.9771\n",
      "Epoch 196/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0640 - accuracy: 0.9806 - val_loss: 0.0886 - val_accuracy: 0.9772\n",
      "Epoch 197/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0650 - accuracy: 0.9801 - val_loss: 0.0892 - val_accuracy: 0.9768\n",
      "Epoch 198/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9809 - val_loss: 0.0868 - val_accuracy: 0.9774\n",
      "Epoch 199/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.0885 - val_accuracy: 0.9773\n",
      "Epoch 200/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9810 - val_loss: 0.0890 - val_accuracy: 0.9770\n",
      "CPU times: user 3min 35s, sys: 20.5 s, total: 3min 55s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d73a4346-8c27-4266-b194-4e5c930ac7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 499us/step - loss: 0.0776 - accuracy: 0.9780\n",
      "CPU times: user 233 ms, sys: 21 ms, total: 254 ms\n",
      "Wall time: 188 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07762116938829422, 0.9779999852180481]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "sns.lineplot(data=df[['accuracy', 'val_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f88c22a8-1733-4e9e-afea-7cb32127b696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuPElEQVR4nO3deXxV9Z3/8dfnLtn3BQgJuyA7AnGrVVFc0Kqo1YL1Zytd/OlUx+U3rVtt7XRm2k7H6ejYyuCI1qql1qVSh9YWN6Z1KSAom+xbWEIIkD252+f3x7kJN/sNZjvh83w88kjOOd977yfnXt588z3fc46oKsYYY9zP09cFGGOM6R4W6MYYM0BYoBtjzABhgW6MMQOEBboxxgwQvr564by8PB05cmRfvbwxxrjS6tWrD6tqflvbOg10EVkMXAEcUtXJbWwX4FHgcqAWuFlVP+rseUeOHMmqVas6a2aMMSaGiOxub1s8Qy7PAHM62H4ZMDb6dQvwRFeKM8YY0z06DXRVXQEc6aDJXOBZdXwAZIlIQXcVaIwxJj7dcVC0ENgbs1wSXWeMMaYXdUegSxvr2ryegIjcIiKrRGRVWVlZN7y0McaYRt0R6CXAsJjlImB/Ww1VdZGqFqtqcX5+mwdpjTHGnKDuCPSlwFfEcRZQoaoHuuF5jTHGdEE80xZ/DcwC8kSkBPg+4AdQ1YXAMpwpi9twpi0u6KlijTHGtK/TQFfVGzrZrsC3uq0iY4zpAdUNIWobQuSnJ+KcPnNcOKKs3XuUzGQ/Y/LTWm0HCIUjHKiop6IuiCrkpiUAUFbVgAL1wTBHawIMzkwiweth66Eqkv1ePCLsOVJLXloiWSl+Nh6oZGphFp8fm9ftv2OfnSlqjHEpVefL40FVqQmESfJ58HmdEdxQOEJFXZDaQJghmUmUVtazctcRqupDJHg95KUlAhAMRwiEIwRCEQKhMKEIJPu9hFXZc6SWdF+Eogwv+Tm5IELJ0Vre315OQzhCXmoCOamJiDhBXVUforohxLHaADsP16AKo/NS8Huguj7I0YpKSiuqqSSNPH8D0xIPkuQTDicUkeVrIFJZyu4aL1t0GKkJwgzZSjUphBWG6QGyqCIcUZaELwBgvOyhXDPwEmasZx8+wlRpMut0NA0kcK7nE0ZIKVWaTBgvg+Uo+xGWR2awRwdz26wxFujG9JpwCBoqweOFpExoqIajO0E8gDjfRcCfAlnROQFHdjTf1tg2Y6izvOY5qK+AUAMc3gIJaZA1HIoXQGI6bFsO298Gjw/SBqOREHW11RwccgEFp55B0v4PqF/5SyQpGxLTCDTUEwrUcSB1PG/5L2B0Si3n7HiUCB68Xg/i8VHZEGFXfQqL/TcwOCOJS44tITlSi3h8pESqSG44TFXQw6NJt7GzCv4u/BwTw5spI5txoS3k6DHKJJcH5O9Zr6O5PfF/WFD/KxRhv6+I2pCHpEgNT4Uv57dyKWd4t/CwPkEAH9lSzUF8lGsG68Nn8VT4C+RQyS8SHiWLarKlikxqCOGlVLOZHXgEgMX+f+ULni1kSC0AdZpABOHvG36Gpg3iJzzGeaG/ckiz8BNmkBwD4P6kh9iTfjbfTnuDuWULnekaMVaO/RqbJt6Jd8c73Lj1fggB9ce3Hxw+i3eL/5Md+w5y/9rowERMR702MYvpl/492SkJfO6N75FWua3Vx2bzvL+wVwcx6S9PU7D/z622X3/BeRScfjFZKQld/0zGwQLdfHYVJVBTBvkTwJ8E4SDUHXXCLjHNCbrKA5B7Cux8Fyr2Qmo+FBbD4IlQcxj2/g3CDU7Y1ZZDoBbyT4WJV0HdMfjDd6C+EsIB5yshFbJHwmU/cWp4cjZU7gdfIngTQMMQCsBNr0DeWPhwEWx/0wnSin2QkgMpuc7jR34eVi2GN/8RCqZBTTmUrgcUZt0Ps+4juPcj/M9d2epXrxp8Bpsv+w0TCjJIfWx6m7vn3kkrKK8N8J39CxnXsA6A2sR8PMEakiK1PLJ9KJsZyfX7nuDcwF/waQgfIQRIARYGj/CKHuUK30q+LcvJppoUaUDUBySwMvx5HgkVMoRyfpuwAhHFSwQvEZKIkE0O+7KuZu3eY9wWepEiyvCIUq1JlGo2+Z4wvtwKphaNQMpySaiOcFrkUw6kjmFnQiFpwTI+NySXMWlDqTswjjcb5uEhTHbtTpITPYRSszgrbxKp6SPJq6hGy04l1QO1idnU1deTFz7CtwoTuW3ORQRqq8h4eTHhpOFocg51yVn4NMzghBRWn3cRdYEQ2ct/T3LamQSTcqgKeag7ehABfn32eYwuKsKz9iAcnkZB1SHnvU4fDB4fP5pyNeSdAnu8sD3L2fnicb48Xk4feS6nDxsJ066CfYWgESjfDkkZkDaEIemDmTdkOEwfApNfgYYqiIQgZzSkDSLFm8i8tOjsvNTHop8RcT7D/mSoPcKpYyZxqscDI/4LIkHnOcJBSB8CIkzwp4CvZ8IcQPrqFnTFxcVq13LpJZGwE7BNX8ec9eMugUAN/G2R03MMB53eoccHKMz+ntPu7R/BsT3Oz6E6qCqF6oNw40uQOwZevwdWPeX84/IlOT1bgKsXwmk3OD3T19o4zHLhd+G8b8P2t+BX17TePvYSuPG3Tm/58ZmQmOG8htcPgWon9O9Y7fR+//ooDQc3I+EGEgjSEPFQGRA2TbiDoSPGUbhhIXy8hGNJRZQnDiNNa0gNH2PP6Pm8HZpGYulHTD20lILazVSRyo7E8dQn5rJOxvFuzXBCVWUUy6ekJ/nISvISCIY5WlNPORm8F3EucXStZwUCeCQCgAdFUN5MuYy8tERStJZdZVU0hJVqUkhP8jIpR9hV5SUlycewzAT2VgTwokzIijAkJ52C3GxyMlLYfLCK2kCYUXmpoEo4EiEtKYHURB/56YlMHJrBnvJadhyuJsnnpS4YJhCKMDIvhQkFGaQkHO+7qSqhUIhgBBQhNdH6dW4iIqtVtbjNbRbo/ZyqE7r1x5w/0b1+qD3i9HyTs53e79blUF3q9Hx9iU6AD5kKZ90Ke1fCL690gjjWsDPh639ywvJHhU5PxJvgPDYScoYA7tkECSnwwjwo3eg8zut3ehvpQ+CCB51AL90IhzfD/jVOrzg52+kBjzof8sc5/4Hs/RDKPoXhZ8PgyVB72OnBp+Y5Pe8j28Eb7V2n5Di/a6ieSpL5eO8xdpXXsvtwDYerG8hNS2RIRhJZKX7KawJsPljFmj1H2VVeiwiMyk1lZ7kzjhoPr0fIS0sgOyWB0fmpeD0eKuuCVNQFSfZ7KcxOpjArGRHnANihqgYSfR4mFGRw6uB0FPj0QCXDclI4ZVAaGUl+DlXVEwhFmFSYSWayv+m16gJh9h6tJSvZT15aIh5PW+flGdM+C/T+7NNlULUfPH5njPbgeiesL/lnyCyEP9wHH7ZxvbM5P3ECe9Pr8JsbQbzOWG044PS0T/+60wOuPQLv/qvzZ2NydvQrC9IGHx/7DdQ6wd1NQuEIu4/UUhcIk5HkJz3JR3lNgC2lTi8zGI5wrDbIGxsOsvNwDRnJPo7VBqlpCJGa4CMl0UtKgg+PwK7yWsIR5zOa5PeQm5pIeU0D9cFI0+vlpycyY3gWpw3LpiEU5pOSCiYXZnL6yGzSk/xsOVhFRV2QEbkpjMpLJSc1gcp65wCaAhMLMkjye7vt9zemJ1mg97VgHax7CTb/welFV+53hgqSs+DZubDjHaedx+eMQ4fqYO7PYfhZzrb9a522gRonsFNynR52/qlOGAdqnKD2ds+fzsdqA5RVNZCTmtA0e8DnFT7afYwtpVX4PMKUokyyUhJ44p1t+L0eRuel8vbmMg5V1RMMa1MId2RCQQYzR2RR0xAmM9lPaqKX2kCY2oYwtcEwwVCEUwal8bkxuYzOT2NQutOjVdWmQM5NSyTNhgzMSaSjQLd/CZ+VKlTug5JVsP8jZwikphy+9gdn+7NXOwcCNQLZo5wDdIUznKENgC/9ygn8cIMT1AmpzZ9/9Cznqz0JKSfcu24IhSmtaGB/RR0HKurYsK+S93eUs/FAZbvDFakJXkIRpSHk9JCHZiaRkujj/e3lfH5sHnMmDyHB62FUXippST6q6kNU1QdJS/QxoSCDjCQ/fp+Q5POSnXpiB4dEhMxkf7OhDGOMBXrXBOtg91+dWR0zb3bWPTbdGSoBZ/w3exRkFDhj014fTLgCCmc6oTzy884BvFhJGc5XNyuramDNnqN8erCKyrog28qqKTlax1mjc6gLRFixtYyyqoZmj0nweZgxPIu7LxrHiNwUjtQESE/yk5boIxCOMH5IOmMHpaEKq3YfZd+xWi6bXECS30s4onhtPNiYPmWB3pn6Cti5Arb8ETa8BoEqSC84HugTr4KMIiiaCYOntJ6SdPo3urecYJg/byylusGZ1qbArsM1HKpqIDPZz75jdawrqeBg5fEJtkl+D8NzUijMSubl1fvweYXZ4wcxJj+NIZlJFGQmU5CVRGFWclxjySJwxqgcIKdpnYW5MX3PAr0j4SD8+yQnxBPSnfCedC2M+NzxNhf/Y7e/bEMozNbSaraXVbO9rMYZsy7M5IOd5by0qoTymkCz9gleD/npiRyrdU47Pmt0DpMLMzltWBaTCzObhXRDKIxHBL/X7g9uzEBjgR6rdAOsed45YeDLv3FOFrjsx84wStHpPXZCQONwxbZDVTz/4R5e+WgfFXVBADzi9MJVwecRZp2az9fOGcWo/FTnDGxgUHpi3AGd6LPZHMYMVBboAHs+gP/9d9j6hjMXevhZzsHNwZNg+v/pkZfcdbiGH76+kdV7jnKsNkhGko/K+hB+r3DppCFcNrmAsYPTGJGbQl0gzPp9lUwcmkHOCR5INMYMfBbof/ouvPefzgyTC77rzN9Oyen8cV1QURvkD+sPsHr3UXxeoeRoHX/beYQEr4erThtKbloiR2sCFGUn88WZRU0XL2qU6PP2yIV8jDEDy8kX6Ac+doZVxl0Cp1wE4690DmrOuKn1lMETVN0QYtGKHazde4xtpVXsr3AOUOalJQDCkMxEri8u4o4LxzI4I6lbXtMYY06eQFeF93/u9Mi9Cc5ZkqdcBMPPdL5O+GmVDfsr+fPGUt7fXk52qp8N+yvZd6yOiQUZnDEqh1MGpXHu2HymFmW2eZ1lY4zpDidHoO/6C/zlZ87lSSdcBVc95pxZ+RkcqQnw4qq9/Or93ew7VocITC3MZGtpA2mJPl78v2dz+sjuHboxxpiODPxAD9bD7/4OgrXOFMOz7wDPiU/Z+3jvMR783TrW73OuKPi5MbncddFYLhg/qNXYtzHG9KaBG+gVJc4Fr9IHw1eXQtoQ51rdJ6CqPsiydQfYUVbD0+/tIj8tkX+4ZBwXjh/MxKHdf5anMcaciIEZ6Ie3wuJLnbnjX/6NcyOEExCOKC+u2ssjf9rM4eoAInDu2Hz+Y95pNn3QGNPvDLxArzsGv54PCFz8wxN+mk9KjnHvy+vYdKCS4hHZ/NdNxUwrymy6b6IxxvQ3cQW6iMwBHgW8wH+r6o9bbM8GFgNjcO7S9zVVXd/NtXZOFX53GxzdBV9Z6txcoYu2lFbxuzX7WLRiB/npiTz+5el8YUqBzU4xxvR7nQa6iHiBnwMX49x2daWILFXVjTHNHgDWquo1IjI+2n52TxTcob89CZuXwaU/gpHndOmhFbVBvvvaen7/8X4AvjC1gH++enKP3czVGGO6Wzw99DOAbaq6A0BElgBzgdhAnwj8CEBVPxWRkSIyWFVLu7vgDpVvc+5DedZtXXrYzsM13PTUhxysqOeui8ZywxnD7YQfY4zrxBPohcDemOUSoOWZOB8D1wJ/EZEzgBFAEdAs0EXkFuAWgOHDh59gyR24/F+de1rGOTyiqryzpYxv//YTIqr89tazmT78s81PN8aYvhLPEb620rHl/Wx+DGSLyFrgDmANEGr1INVFqlqsqsX5+fldrbV9+9fAx7+BSCTuKyLWBcJct/B9Fjy9kiS/hxf/71kW5sYYV4unh14CDItZLgL2xzZQ1UpgAYA4Rw93Rr96x1v/DAfWwvgvODdYjsM/L9vI6t1H+eHVk5lXPIwEn81eMca4WzwpthIYKyKjRCQBmA8sjW0gIlnRbQDfAFZEQ77n1RyG7W/BjK/EHeZ/XH+Q5z7Ywy3njeams0ZYmBtjBoROe+iqGhKR24E3cKYtLlbVDSJya3T7QmAC8KyIhHEOln69B2tubtNS0DBMuiau5h/tOcpdv1nDtGFZ/L9Luj6t0Rhj+qu45qGr6jJgWYt1C2N+fh8Y272lxWnDq5A7FgZP7rCZqrL04/089Lv1DM5I4qmvFtvde4wxA4q7xxqqDzlXUpx0TaczWx57cxt3LlnL6Pw0nvv6mXYhLWPMgOPuU/8T0uDLL8KgCR02K6tqYOG727ls8hAe//IMu0O9MWZAcnmgp8DYiztttvDd7TSEwnz70lMtzI0xA5a7h1ze+TF8+j8dNjlQUcdzH+zmmulFjM6PbxaMMca4kXsDPVgPK/4N9n7YYbOfvrEZBe66qG+O2RpjTG9xb6AfXAeRIBQWt9tk/b4KXl2zjwXnjGRYTkovFmeMMb3PvYG+b5Xzvaj9QP/JHz8lK9nP3806pZeKMsaYvuPeQC9ZBelDIWNom5tX7z7C/249zK3njyEz2d/LxRljTO9zb6Af3gxD2j+Z6D+WbyU3NYGbzh7Ri0UZY0zfce+0xQsehITUNjd9erCS/916mPsvG09Kgnt/RWOM6Qr3pt2pl7W76Y/rDyIC184o6sWCjDGmb7l3yOWjXznXQW/DnzaUMnN4Nvnpdnq/Mebk4c5AV4Wld8Cny1pt2nuklo0HKrl00pA+KMwYY/qOOwM9WAdom2Pof97o3PXu4omDe7koY4zpWy4N9FrnexuB/tanhxg7KI2ReW0fMDXGmIHKnYEeqHa+twj0+mCYlbuOcO7YbrxfqTHGuIRLAz3aQ/c3P53/oz1HaQhFOOeU3D4oyhhj+pY7Az0xDabfBDmjm61+b1s5Xo9wxqicPirMGGP6jjvnoWcNh7mPt1r93vbDTC3KJD3JTvU3xpx83NlDr6+A8u0QCjStqqoP8nFJBZ8bY8MtxpiTU1yBLiJzRGSziGwTkfva2J4pIr8XkY9FZIOILOj+UmNseQP+cwYc2920al1JBeGIcuYoC3RjzMmp00AXES/wc+AyYCJwg4hMbNHsW8BGVZ0GzAIeEZGEbq71uECN8z1mlsvWQ87Ml/FD0nvsZY0xpj+Lp4d+BrBNVXeoagBYAsxt0UaBdBERIA04AoS6tdJYjYEeM8tlS2kVmcl+O93fGHPSiifQC4G9Mcsl0XWxHgcmAPuBdcCdqhpp+UQicouIrBKRVWVlZSdYMm2eWLT1UDVjB6Xh/J9ijDEnn3gCva2E1BbLlwJrgaHAacDjIpLR6kGqi1S1WFWL8/M/w8k/gWrwJoD3+GyWbYeqGTvYbgJtjDl5xRPoJcCwmOUinJ54rAXAK+rYBuwExndPiW1IzID8U5sWD1c3cKQmwCmDbPzcGHPyiifQVwJjRWRU9EDnfGBpizZ7gNkAIjIYOBXY0Z2FNnPeP8Ctf2la3FrqHBAdZz10Y8xJrNMTi1Q1JCK3A28AXmCxqm4QkVuj2xcCPwSeEZF1OEM096rq4R6su5lth6oAGGs9dGPMSSyuM0VVdRmwrMW6hTE/7wcu6d7SOvDbBc5MlxtfBGBLaTXpiT4GZ9gMF2PMycudp/5XHQSPt2lxx+FqxtgMF2PMSc6dp/4HqpvNQT9U2cCQjKQ+LMgYY/qeOwM9WNtsDvrh6gby0nvuxFRjjHEDdwZ6oKYp0EPhCEdrg+Sm2vi5Mebk5tJAP95DP1LjXHExz075N8ac5Nx5UPTv1zQdFC2rbgAgL9WGXIwxJzd3Bnrq8UvklldbD90YY8CNQy71lfDiV2D7W4BzQBQgL80C3RhzcnNhoFfAxtegogQ4Hui5aTbkYow5ubkv0Fvc3KK8OkCCz0N6ojtHj4wxpru4L9CDjTe3cAK9rLqBvNQEO0vUGHPSc1+gt+ihH64O2AFRY4zB1YHunPpfXt1gB0SNMQY3BnrBaXDd05AzGnAOiubaHHRjjHHhPPSMAph8LQCqSrkNuRhjDODGHnqMirogoYhaD90YY3B5oDfOQc+3Hroxxrg90J3T/u1Ki8YY4/JAr6oPAZCR7L5DAcYY091cHeh1wTAAKQneTloaY8zA5+5ADzg99CS/BboxxsQV6CIyR0Q2i8g2Ebmvje3fFpG10a/1IhIWkZzuL7e52kBjD92GXIwxptNAFxEv8HPgMmAicIOITIxto6o/VdXTVPU04H7gXVU90gP1NmNDLsYYc1w8PfQzgG2qukNVA8ASYG4H7W8Aft0dxXWmLhBGBBJ9rh45MsaYbhFPEhYCe2OWS6LrWhGRFGAO8HI7228RkVUisqqsrKyrtbZSFwiT7PfalRaNMYb4Ar2ttNR22l4J/LW94RZVXaSqxapanJ+fH2+N7aoNhm24xRhjouIJ9BJgWMxyEbC/nbbz6aXhFnB66DbDxRhjHPEE+kpgrIiMEpEEnNBe2rKRiGQC5wOvdW+J7asLWA/dGGMadTrfT1VDInI78AbgBRar6gYRuTW6fWG06TXAn1S1pseqbaE26IyhG2OMifPyuaq6DFjWYt3CFsvPAM90V2HxqA+ESbYeujHGAC4/U7Q2GLKTiowxJsrdgR6wIRdjjGnk6kC3IRdjjDnO1YFuB0WNMeY4Vwe6TVs0xpjjXBvo4YjSEIrYkIsxxkS5NtAbr7RoQy7GGONwb6AH7NK5xhgTy/WBbtdyMcYYh3sDPWh3KzLGmFiuDfTa6P1EbcjFGGMcrg30xh66DbkYY4zDvYFuB0WNMaYZ1wZ6bTTQbR66McY4XBvoNg/dGGOac2+g25CLMcY0495AD9qQizHGxHJtoDeOoSf5LNCNMQZcHOh1gRBJfg8ej/R1KcYY0y+4N9CDYTtL1BhjYsQV6CIyR0Q2i8g2EbmvnTazRGStiGwQkXe7t8zW7PZzxhjTXKddXBHxAj8HLgZKgJUislRVN8a0yQJ+AcxR1T0iMqiH6m1SH7TbzxljTKx4euhnANtUdYeqBoAlwNwWbb4MvKKqewBU9VD3ltlard2tyBhjmokn0AuBvTHLJdF1scYB2SLyjoisFpGvtPVEInKLiKwSkVVlZWUnVnFUbSBs13ExxpgY8QR6W9NItMWyD5gJfAG4FHhIRMa1epDqIlUtVtXi/Pz8Lhcbq95uEG2MMc3EM02kBBgWs1wE7G+jzWFVrQFqRGQFMA3Y0i1VtiEQipDgc+0kHWOM6XbxJOJKYKyIjBKRBGA+sLRFm9eAc0XEJyIpwJnApu4ttblQRPF7bQ66McY06rSHrqohEbkdeAPwAotVdYOI3BrdvlBVN4nIH4FPgAjw36q6vicLD4Uj+DzWQzfGmEZxnZmjqsuAZS3WLWyx/FPgp91XWsdCEcVnZ4kaY0wT13ZxQ2HFZ0MuxhjTxL2BHong87q2fGOM6XauTUQbcjHGmObcG+hhtYOixhgTw7WJGAxHbNqiMcbEcG2ghyOK14ZcjDGmiSsDXVWdMXQ7KGqMMU1cmYjhiHMpGb/10I0xpokrAz0UDXSvjaEbY0wTVwZ6MBwBwG+zXIwxpokrE7FxyMXOFDXGmONcGejBcDTQbQzdGGOauDLQQxFnyMVmuRhjzHGuTMSQ9dCNMaYVdwa6jaEbY0wr7gz06CwXu5aLMcYc58pEbOyh27VcjDHmOHcGenQM3Ws9dGOMaeLKRAw2zXKxHroxxjRyZaA3nVhks1yMMaZJXIEuInNEZLOIbBOR+9rYPktEKkRkbfTre91f6nFBOyhqjDGt+DprICJe4OfAxUAJsFJElqrqxhZN/1dVr+iBGltpHEO3g6LGGHNcPF3cM4BtqrpDVQPAEmBuz5bVscYhF7vBhTHGHBdPoBcCe2OWS6LrWjpbRD4WkT+IyKRuqa4dTVdbtFP/jTGmSadDLkBb3WBtsfwRMEJVq0XkcuB3wNhWTyRyC3ALwPDhw7tWaQw7U9QYY1qLp4tbAgyLWS4C9sc2UNVKVa2O/rwM8ItIXssnUtVFqlqsqsX5+fknXHTIZrkYY0wr8QT6SmCsiIwSkQRgPrA0toGIDBERif58RvR5y7u72EZ26r8xxrTW6ZCLqoZE5HbgDcALLFbVDSJya3T7QuA64DYRCQF1wHxVbTks022arrZoQy7GGNMknjH0xmGUZS3WLYz5+XHg8e4trX3Hh1ysh26MMY1cmYghO/XfGGNacWegN55YZD10Y4xp4spEbOyhe62HbowxTVwZ6HaTaGOMac2VgR5uusGFK8s3xpge4cpEbJyHbh10Y4w5zpWBHowofq8QPZfJGGMMLg30cERtDroxxrTgylQMhiN2QNQYY1pwZaCHwmonFRljTAvuDPSI4rMZLsYY04wrUzFkQy7GGNOKOwM9YkMuxhjTkmsD3a7jYowxzbkyFUPhiN0g2hhjWnBloAfDdlDUGGNacmUqhiN2UNQYY1pyZaDbQVFjjGnNlYEeDEfsoKgxxrTgylQMR9QOihpjTAuuDPSgnfpvjDGtxBXoIjJHRDaLyDYRua+DdqeLSFhEruu+ElsLRSJ2cwtjjGnB11kDEfECPwcuBkqAlSKyVFU3ttHuJ8AbPVForFDYhlyM6W7BYJCSkhLq6+v7uhQDJCUlUVRUhN/vj/sxnQY6cAawTVV3AIjIEmAusLFFuzuAl4HT4371ExSK3uDCGNN9SkpKSE9PZ+TIkXbzmD6mqpSXl1NSUsKoUaPiflw84xaFwN6Y5ZLouiYiUghcAyzs6IlE5BYRWSUiq8rKyuIusiW7wYUx3a++vp7c3FwL835ARMjNze3yX0vxpGJb7662WP4P4F5VDXf0RKq6SFWLVbU4Pz8/zhJbsxtcGNMzLMz7jxN5L+IZcikBhsUsFwH7W7QpBpZEC8gDLheRkKr+rssVxcFucGGMMa3FE+grgbEiMgrYB8wHvhzbQFWbBnlE5Bng9Z4Kc7AbXBhjTFs6DXRVDYnI7TizV7zAYlXdICK3Rrd3OG7eE0J2LRdjzGcQCoXw+eLpz7pLXL+Rqi4DlrVY12aQq+rNn72sjoXCdlDUmJ70g99vYOP+ym59zolDM/j+lZM6bXf11Vezd+9e6uvrufPOO7nlllv44x//yAMPPEA4HCYvL48333yT6upq7rjjDlatWoWI8P3vf58vfvGLpKWlUV1dDcBLL73E66+/zjPPPMPNN99MTk4Oa9asYcaMGcybN4+77rqLuro6kpOTefrppzn11FMJh8Pce++9vPHGG4gI3/zmN5k4cSKPP/44r776KgB//vOfeeKJJ3jllVe6dR99Vq78L8o5sch66MYMRIsXLyYnJ4e6ujpOP/105s6dyze/+U1WrFjBqFGjOHLkCAA//OEPyczMZN26dQAcPXq00+fesmULy5cvx+v1UllZyYoVK/D5fCxfvpwHHniAl19+mUWLFrFz507WrFmDz+fjyJEjZGdn861vfYuysjLy8/N5+umnWbBgQY/uhxPhzkC3E4uM6VHx9KR7ymOPPdbUE967dy+LFi3ivPPOa5qPnZOTA8Dy5ctZsmRJ0+Oys7M7fe7rr78er9cLQEVFBV/96lfZunUrIkIwGGx63ltvvbVpSKbx9W666Saee+45FixYwPvvv8+zzz7bTb9x93FdoKuqHRQ1ZoB65513WL58Oe+//z4pKSnMmjWLadOmsXnz5lZtVbXNqX2x61rO405NTW36+aGHHuKCCy7g1VdfZdeuXcyaNavD512wYAFXXnklSUlJXH/99f1yDN51qRiOOFPg/dZDN2bAqaioIDs7m5SUFD799FM++OADGhoaePfdd9m5cydA05DLJZdcwuOPP9702MYhl8GDB7Np0yYikUhTT7+91yosdM6RfOaZZ5rWX3LJJSxcuJBQKNTs9YYOHcrQoUP5p3/6J26++eZu+527k+sCPRQNdK+NoRsz4MyZM4dQKMTUqVN56KGHOOuss8jPz2fRokVce+21TJs2jXnz5gHw3e9+l6NHjzJ58mSmTZvG22+/DcCPf/xjrrjiCi688EIKCgrafa3vfOc73H///ZxzzjmEw8fPifzGN77B8OHDmTp1KtOmTeOFF15o2nbjjTcybNgwJk6c2EN74LMR1ZYnffaO4uJiXbVqVZcfV1UfZMrDf+LByyfwzfNG90BlxpycNm3axIQJE/q6jH7t9ttvZ/r06Xz961/vlddr6z0RkdWqWtxW+/43CNSJxiEXO1PUGNObZs6cSWpqKo888khfl9Iu1wV6MBwNdBtDN8b0otWrV/d1CZ1y4Rh6BMBmuRhjTAuuS8VQtIdu89CNMaY59wV647RFG0M3xphm3Bfo4eiQi13LxRhjmnFdKjb20O2gqDHGNOe+QG+c5WIHRY05qaWlpfV1Cf2O+6YtNs1ysR66MT3q6S+0vX7B/zjf/3AfHFzXevucH0HBVFjzPKx9ofXjBpj+dG1113VzwzbkYsyAdO+99/KLX/yiafnhhx/mBz/4AbNnz2bGjBlMmTKF1157La7nqq6ubvdxzz77bNNp/TfddBMApaWlXHPNNUybNo1p06bx3nvvsWvXLiZPntz0uH/7t3/j4YcfBmDWrFk88MADnH/++Tz66KP8/ve/58wzz2T69OlcdNFFlJaWNtWxYMECpkyZwtSpU3n55Zd56qmnuPvuu5ue98knn+See+454f3WjKr2ydfMmTP1RPx1W5mOuPd1fW/b4RN6vDGmbRs3buzT1//oo4/0vPPOa1qeMGGC7t69WysqKlRVtaysTMeMGaORSERVVVNTU9t9rmAw2Obj1q9fr+PGjdOysjJVVS0vL1dV1S996Uv6s5/9TFVVQ6GQHjt2THfu3KmTJk1qes6f/vSn+v3vf19VVc8//3y97bbbmrYdOXKkqa4nn3xS77nnHlVV/c53vqN33nlns3bV1dU6evRoDQQCqqp69tln6yeffNLm79HWewKs0nZytX/8ndAFjWPoNm3RmIFl+vTpHDp0iP3791NWVkZ2djYFBQXcfffdrFixAo/Hw759+ygtLWXIkCEdPpeq8sADD7R63FtvvcV1111HXl4ecPxa52+99VbT9c29Xi+ZmZmd3jCj8SJhACUlJcybN48DBw4QCASart3e3jXbL7zwQl5//XUmTJhAMBhkypQpXdxbbXNdoDcOudiJRcYMPNdddx0vvfQSBw8eZP78+Tz//POUlZWxevVq/H4/I0eObHWN87a09zht51rnbfH5fESix+yg42ur33HHHdxzzz1cddVVvPPOO01DM+293je+8Q3+5V/+hfHjx3frnY9cN4YejM5D99ssF2MGnPnz57NkyRJeeuklrrvuOioqKhg0aBB+v5+3336b3bt3x/U87T1u9uzZvPjii5SXlwPHr3U+e/ZsnnjiCQDC4TCVlZUMHjyYQ4cOUV5eTkNDA6+//nqHr9d4bfVf/vKXTevbu2b7mWeeyd69e3nhhRe44YYb4t09nYorFUVkjohsFpFtInJfG9vnisgnIrJWRFaJyOe7rcIW7GqLxgxckyZNoqqqisLCQgoKCrjxxhtZtWoVxcXFPP/884wfPz6u52nvcZMmTeLBBx/k/PPPZ9q0aU0HIx999FHefvttpkyZwsyZM9mwYQN+v5/vfe97nHnmmVxxxRUdvvbDDz/M9ddfz7nnnts0nAPtX7Md4Etf+hLnnHNOXLfOi1en10MXES+wBbgYKAFWAjeo6saYNmlAjaqqiEwFXlTVDvf8iV4PffXuozz1lx189wsTGZqV3OXHG2PaZtdD711XXHEFd999N7Nnz263TVevhx5PD/0MYJuq7lDVALAEmBvbQFWr9fj/DKlAj901Y+aIbH5x40wLc2OMKx07doxx48aRnJzcYZifiHgOihYCe2OWS4AzWzYSkWuAHwGDgDbPSBCRW4BbAIYPH97VWo0xppl169Y1zSVvlJiYyIcffthHFXUuKyuLLVu29MhzxxPobQ1Wt+qBq+qrwKsich7wQ+CiNtosAhaBM+TStVKNMT2tK7NA+oMpU6awdu3avi6jR3Q2HN6WeIZcSoBhMctFwP4OilgBjBGRvPbaGGP6n6SkJMrLy08oSEz3UlXKy8tJSkrq0uPi6aGvBMaKyChgHzAf+HJsAxE5BdgePSg6A0gAyrtUiTGmTxUVFVFSUkJZWVlfl2Jw/oMtKirq0mM6DXRVDYnI7cAbgBdYrKobROTW6PaFwBeBr4hIEKgD5qn9N2+Mq/j9/qYzHI07dTptsaec6LRFY4w5mX3WaYvGGGNcwALdGGMGiD4bchGRMiC+CzO0lgcc7sZyulN/rc3q6pr+Whf039qsrq450bpGqGp+Wxv6LNA/CxFZ1d4YUl/rr7VZXV3TX+uC/lub1dU1PVGXDbkYY8wAYYFujDEDhFsDfVFfF9CB/lqb1dU1/bUu6L+1WV1d0+11uXIM3RhjTGtu7aEbY4xpwQLdGGMGCNcFeme3w+vFOoaJyNsisklENojIndH1D4vIvujt+NaKyOV9UNsuEVnXeEvA6LocEfmziGyNfu+++17FX9epMftlrYhUishdfbHPRGSxiBwSkfUx69rdRyJyf/Qzt1lELu3lun4qIp9Gb/P4qohkRdePFJG6mP22sJfravd966391UFtv4mpa5eIrI2u75V91kE+9OxnTFVd84VzcbDtwGicKzp+DEzso1oKgBnRn9NxbtM3EXgY+Ic+3k+7gLwW6/4VuC/6833AT/rBe3kQGNEX+ww4D5gBrO9sH0Xf14+BRGBU9DPo7cW6LgF80Z9/ElPXyNh2fbC/2nzfenN/tVdbi+2PAN/rzX3WQT706GfMbT30Tm+H11tU9YCqfhT9uQrYhHN3p/5qLtB4O/JfAlf3XSkAzMa55PKJni38mahz3f4jLVa3t4/mAktUtUFVdwLbcD6LvVKXqv5JVUPRxQ9w7knQq9rZX+3ptf3VWW3i3K3jS8Cve+r126mpvXzo0c+Y2wK9rdvh9XmIishIYDrQeN+r26N/Hi/ui6ENnDtK/UlEVkdv+wcwWFUPgPNhw7lVYF+aT/N/ZH29z6D9fdSfPndfA/4QszxKRNaIyLsicm4f1NPW+9af9te5QKmqbo1Z16v7rEU+9OhnzG2BHtft8HqTiKQBLwN3qWol8AQwBjgNOIDz515vO0dVZwCXAd8S57aA/YaIJABXAb+NruoP+6wj/eJzJyIPAiHg+eiqA8BwVZ0O3AO8ICIZvVhSe+9bv9hfUTfQvOPQq/usjXxot2kb67q8z9wW6F26HV5PExE/zpv1vKq+AqCqpaoaVtUI8CQ9+Kdme1R1f/T7IeDVaA2lIlIQrbsAONTbdcW4DPhIVUuhf+yzqPb2UZ9/7kTkq8AVwI0aHXSN/nleHv15Nc6467jeqqmD963P9xeAiPiAa4HfNK7rzX3WVj7Qw58xtwV60+3wor28+cDSvigkOjb3FLBJVf89Zn1BTLNrgPUtH9vDdaWKSHrjzzgH1Nbj7KevRpt9FXitN+tqoVmvqa/3WYz29tFSYL6IJIpzK8axwN96qygRmQPcC1ylqrUx6/NFxBv9eXS0rh29WFd771uf7q8YFwGfqmpJ44re2mft5QM9/Rnr6aO9PXD0+HKcI8bbgQf7sI7P4/xJ9AmwNvp1OfArYF10/VKgoJfrGo1ztPxjYEPjPgJygTeBrdHvOX2031Jw7jebGbOu1/cZzn8oB4AgTu/o6x3tI+DB6GduM3BZL9e1DWd8tfFztjDa9ovR9/hj4CPgyl6uq933rbf2V3u1Rdc/A9zaom2v7LMO8qFHP2N26r8xxgwQbhtyMcYY0w4LdGOMGSAs0I0xZoCwQDfGmAHCAt0YYwYIC3RjjBkgLNCNMWaA+P+cm7YH72ePhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f419e384-f82f-4ac4-8b81-5d2f2fb8170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MNIST-2H\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_01 (Dense)      (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_02 (Dense)      (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_03 (Dense)      (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "ouput_layer (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential(name='MNIST-2H')\n",
    "for layer in [\n",
    "    tf.keras.layers.Dense(N_HIDDEN, name='hidden_layer_01', input_shape=(x_train.shape[1],),  activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROP_OUT),\n",
    "    tf.keras.layers.Dense(N_HIDDEN, name='hidden_layer_02', activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROP_OUT),\n",
    "    tf.keras.layers.Dense(N_HIDDEN, name='hidden_layer_03', activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROP_OUT),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, name='ouput_layer', activation='softmax'),\n",
    "]: model.add(layer)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c511a1ef-c709-49db-b7db-4cac2b313c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.8196 - val_loss: 0.1818 - val_accuracy: 0.9463\n",
      "Epoch 2/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.9266 - val_loss: 0.1382 - val_accuracy: 0.9592\n",
      "Epoch 3/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9427 - val_loss: 0.1202 - val_accuracy: 0.9664\n",
      "Epoch 4/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9530 - val_loss: 0.1038 - val_accuracy: 0.9703\n",
      "Epoch 5/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.9585 - val_loss: 0.1000 - val_accuracy: 0.9728\n",
      "Epoch 6/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1314 - accuracy: 0.9617 - val_loss: 0.0941 - val_accuracy: 0.9732\n",
      "Epoch 7/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1177 - accuracy: 0.9655 - val_loss: 0.0924 - val_accuracy: 0.9737\n",
      "Epoch 8/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9669 - val_loss: 0.0935 - val_accuracy: 0.9744\n",
      "Epoch 9/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9681 - val_loss: 0.0935 - val_accuracy: 0.9742\n",
      "Epoch 10/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9703 - val_loss: 0.0897 - val_accuracy: 0.9757\n",
      "Epoch 11/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9723 - val_loss: 0.0873 - val_accuracy: 0.9773\n",
      "Epoch 12/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9724 - val_loss: 0.0853 - val_accuracy: 0.9776\n",
      "Epoch 13/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0819 - accuracy: 0.9750 - val_loss: 0.0855 - val_accuracy: 0.9768\n",
      "Epoch 14/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9760 - val_loss: 0.0865 - val_accuracy: 0.9766\n",
      "Epoch 15/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9765 - val_loss: 0.0853 - val_accuracy: 0.9763\n",
      "Epoch 16/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0717 - accuracy: 0.9780 - val_loss: 0.0808 - val_accuracy: 0.9792\n",
      "Epoch 17/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9776 - val_loss: 0.0807 - val_accuracy: 0.9793\n",
      "Epoch 18/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9782 - val_loss: 0.0875 - val_accuracy: 0.9775\n",
      "Epoch 19/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0684 - accuracy: 0.9781 - val_loss: 0.0805 - val_accuracy: 0.9787\n",
      "Epoch 20/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.0847 - val_accuracy: 0.9780\n",
      "Epoch 21/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.0816 - val_accuracy: 0.9794\n",
      "Epoch 22/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9812 - val_loss: 0.0869 - val_accuracy: 0.9783\n",
      "Epoch 23/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9818 - val_loss: 0.0845 - val_accuracy: 0.9785\n",
      "Epoch 24/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.0855 - val_accuracy: 0.9782\n",
      "Epoch 25/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
      "Epoch 26/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.0834 - val_accuracy: 0.9785\n",
      "Epoch 27/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0888 - val_accuracy: 0.9780\n",
      "Epoch 28/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.0841 - val_accuracy: 0.9793\n",
      "Epoch 29/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.0870 - val_accuracy: 0.9791\n",
      "Epoch 30/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0911 - val_accuracy: 0.9783\n",
      "Epoch 31/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0480 - accuracy: 0.9844 - val_loss: 0.0947 - val_accuracy: 0.9787\n",
      "Epoch 32/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 0.0880 - val_accuracy: 0.9788\n",
      "Epoch 33/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0931 - val_accuracy: 0.9785\n",
      "Epoch 34/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.0894 - val_accuracy: 0.9775\n",
      "Epoch 35/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.0928 - val_accuracy: 0.9776\n",
      "Epoch 36/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.0908 - val_accuracy: 0.9784\n",
      "Epoch 37/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.0919 - val_accuracy: 0.9798\n",
      "Epoch 38/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 0.0928 - val_accuracy: 0.9784\n",
      "Epoch 39/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.0879 - val_accuracy: 0.9787\n",
      "Epoch 40/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.0872 - val_accuracy: 0.9795\n",
      "Epoch 41/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0879 - val_accuracy: 0.9795\n",
      "Epoch 42/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.0891 - val_accuracy: 0.9795\n",
      "Epoch 43/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.0943 - val_accuracy: 0.9787\n",
      "Epoch 44/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0944 - val_accuracy: 0.9783\n",
      "Epoch 45/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.0885 - val_accuracy: 0.9795\n",
      "Epoch 46/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 0.0885 - val_accuracy: 0.9803\n",
      "Epoch 47/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9882 - val_loss: 0.0890 - val_accuracy: 0.9794\n",
      "Epoch 48/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9892 - val_loss: 0.0938 - val_accuracy: 0.9784\n",
      "Epoch 49/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.0898 - val_accuracy: 0.9791\n",
      "Epoch 50/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0913 - val_accuracy: 0.9794\n",
      "Epoch 51/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.0936 - val_accuracy: 0.9773\n",
      "Epoch 52/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.0864 - val_accuracy: 0.9807\n",
      "Epoch 53/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0931 - val_accuracy: 0.9796\n",
      "Epoch 54/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.0953 - val_accuracy: 0.9797\n",
      "Epoch 55/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0880 - val_accuracy: 0.9804\n",
      "Epoch 56/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 0.0901 - val_accuracy: 0.9792\n",
      "Epoch 57/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0997 - val_accuracy: 0.9789\n",
      "Epoch 58/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.1004 - val_accuracy: 0.9791\n",
      "Epoch 59/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0957 - val_accuracy: 0.9787\n",
      "Epoch 60/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0942 - val_accuracy: 0.9793\n",
      "Epoch 61/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.0969 - val_accuracy: 0.9803\n",
      "Epoch 62/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0894 - val_accuracy: 0.9797\n",
      "Epoch 63/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.0954 - val_accuracy: 0.9791\n",
      "Epoch 64/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.0950 - val_accuracy: 0.9801\n",
      "Epoch 65/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 0.1074 - val_accuracy: 0.9787\n",
      "Epoch 66/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.1041 - val_accuracy: 0.9790\n",
      "Epoch 67/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.1027 - val_accuracy: 0.9797\n",
      "Epoch 68/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0958 - val_accuracy: 0.9808\n",
      "Epoch 69/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0325 - accuracy: 0.9904 - val_loss: 0.0965 - val_accuracy: 0.9791\n",
      "Epoch 70/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.0966 - val_accuracy: 0.9796\n",
      "Epoch 71/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.0922 - val_accuracy: 0.9800\n",
      "Epoch 72/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.0956 - val_accuracy: 0.9797\n",
      "Epoch 73/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.1003 - val_accuracy: 0.9793\n",
      "Epoch 74/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.0976 - val_accuracy: 0.9805\n",
      "Epoch 75/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.1000 - val_accuracy: 0.9785\n",
      "Epoch 76/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0955 - val_accuracy: 0.9793\n",
      "Epoch 77/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0980 - val_accuracy: 0.9787\n",
      "Epoch 78/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.1016 - val_accuracy: 0.9780\n",
      "Epoch 79/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.1003 - val_accuracy: 0.9793\n",
      "Epoch 80/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0973 - val_accuracy: 0.9789\n",
      "Epoch 81/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.1001 - val_accuracy: 0.9790\n",
      "Epoch 82/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.1053 - val_accuracy: 0.9797\n",
      "Epoch 83/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0998 - val_accuracy: 0.9788\n",
      "Epoch 84/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.1037 - val_accuracy: 0.9777\n",
      "Epoch 85/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0279 - accuracy: 0.9917 - val_loss: 0.1011 - val_accuracy: 0.9781\n",
      "Epoch 86/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.1035 - val_accuracy: 0.9775\n",
      "Epoch 87/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9919 - val_loss: 0.0996 - val_accuracy: 0.9792\n",
      "Epoch 88/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.1069 - val_accuracy: 0.9779\n",
      "Epoch 89/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0282 - accuracy: 0.9914 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 90/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.0970 - val_accuracy: 0.9783\n",
      "Epoch 91/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0976 - val_accuracy: 0.9789\n",
      "Epoch 92/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0996 - val_accuracy: 0.9786\n",
      "Epoch 93/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0999 - val_accuracy: 0.9792\n",
      "Epoch 94/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.1131 - val_accuracy: 0.9793\n",
      "Epoch 95/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.1036 - val_accuracy: 0.9792\n",
      "Epoch 96/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0983 - val_accuracy: 0.9792\n",
      "Epoch 97/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
      "Epoch 98/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0982 - val_accuracy: 0.9791\n",
      "Epoch 99/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.1043 - val_accuracy: 0.9793\n",
      "Epoch 100/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0975 - val_accuracy: 0.9797\n",
      "Epoch 101/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.1043 - val_accuracy: 0.9789\n",
      "Epoch 102/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0992 - val_accuracy: 0.9792\n",
      "Epoch 103/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.1001 - val_accuracy: 0.9803\n",
      "Epoch 104/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.1028 - val_accuracy: 0.9792\n",
      "Epoch 105/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.1031 - val_accuracy: 0.9794\n",
      "Epoch 106/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.1071 - val_accuracy: 0.9784\n",
      "Epoch 107/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.1049 - val_accuracy: 0.9793\n",
      "Epoch 108/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.1113 - val_accuracy: 0.9792\n",
      "Epoch 109/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.1126 - val_accuracy: 0.9772\n",
      "Epoch 110/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.1057 - val_accuracy: 0.9806\n",
      "Epoch 111/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.1099 - val_accuracy: 0.9783\n",
      "Epoch 112/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.1057 - val_accuracy: 0.9783\n",
      "Epoch 113/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.1040 - val_accuracy: 0.9795\n",
      "Epoch 114/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.1066 - val_accuracy: 0.9786\n",
      "Epoch 115/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.1083 - val_accuracy: 0.9793\n",
      "Epoch 116/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.1079 - val_accuracy: 0.9793\n",
      "Epoch 117/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.1091 - val_accuracy: 0.9793\n",
      "Epoch 118/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.1128 - val_accuracy: 0.9791\n",
      "Epoch 119/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0995 - val_accuracy: 0.9793\n",
      "Epoch 120/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.1048 - val_accuracy: 0.9801\n",
      "Epoch 121/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.1021 - val_accuracy: 0.9795\n",
      "Epoch 122/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.1091 - val_accuracy: 0.9788\n",
      "Epoch 123/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.1094 - val_accuracy: 0.9788\n",
      "Epoch 124/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.1138 - val_accuracy: 0.9780\n",
      "Epoch 125/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.1068 - val_accuracy: 0.9797\n",
      "Epoch 126/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.1108 - val_accuracy: 0.9786\n",
      "Epoch 127/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.1104 - val_accuracy: 0.9793\n",
      "Epoch 128/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.1091 - val_accuracy: 0.9784\n",
      "Epoch 129/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.1061 - val_accuracy: 0.9792\n",
      "Epoch 130/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.1117 - val_accuracy: 0.9793\n",
      "Epoch 131/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 0.1046 - val_accuracy: 0.9801\n",
      "Epoch 132/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.1130 - val_accuracy: 0.9787\n",
      "Epoch 133/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.1189 - val_accuracy: 0.9779\n",
      "Epoch 134/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.1026 - val_accuracy: 0.9790\n",
      "Epoch 135/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.1044 - val_accuracy: 0.9790\n",
      "Epoch 136/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.1067 - val_accuracy: 0.9782\n",
      "Epoch 137/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.1099 - val_accuracy: 0.9791\n",
      "Epoch 138/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.1017 - val_accuracy: 0.9788\n",
      "Epoch 139/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.1042 - val_accuracy: 0.9793\n",
      "Epoch 140/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.1093 - val_accuracy: 0.9787\n",
      "Epoch 141/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.1092 - val_accuracy: 0.9794\n",
      "Epoch 142/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.1105 - val_accuracy: 0.9799\n",
      "Epoch 143/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.1025 - val_accuracy: 0.9808\n",
      "Epoch 144/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.1108 - val_accuracy: 0.9799\n",
      "Epoch 145/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.1169 - val_accuracy: 0.9793\n",
      "Epoch 146/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.1101 - val_accuracy: 0.9798\n",
      "Epoch 147/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.1101 - val_accuracy: 0.9786\n",
      "Epoch 148/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.1133 - val_accuracy: 0.9793\n",
      "Epoch 149/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.1173 - val_accuracy: 0.9795\n",
      "Epoch 150/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.1074 - val_accuracy: 0.9791\n",
      "Epoch 151/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.1144 - val_accuracy: 0.9783\n",
      "Epoch 152/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.1092 - val_accuracy: 0.9799\n",
      "Epoch 153/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.1175 - val_accuracy: 0.9783\n",
      "Epoch 154/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.1136 - val_accuracy: 0.9805\n",
      "Epoch 155/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.1177 - val_accuracy: 0.9797\n",
      "Epoch 156/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.1066 - val_accuracy: 0.9804\n",
      "Epoch 157/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.1160 - val_accuracy: 0.9795\n",
      "Epoch 158/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.1043 - val_accuracy: 0.9808\n",
      "Epoch 159/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.1208 - val_accuracy: 0.9790\n",
      "Epoch 160/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.1102 - val_accuracy: 0.9808\n",
      "Epoch 161/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.1098 - val_accuracy: 0.9788\n",
      "Epoch 162/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.1176 - val_accuracy: 0.9783\n",
      "Epoch 163/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.0987 - val_accuracy: 0.9799\n",
      "Epoch 164/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.1141 - val_accuracy: 0.9797\n",
      "Epoch 165/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.1188 - val_accuracy: 0.9783\n",
      "Epoch 166/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.1132 - val_accuracy: 0.9795\n",
      "Epoch 167/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.1173 - val_accuracy: 0.9793\n",
      "Epoch 168/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.1170 - val_accuracy: 0.9788\n",
      "Epoch 169/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.1163 - val_accuracy: 0.9788\n",
      "Epoch 170/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.1136 - val_accuracy: 0.9797\n",
      "Epoch 171/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.1141 - val_accuracy: 0.9788\n",
      "Epoch 172/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.1169 - val_accuracy: 0.9782\n",
      "Epoch 173/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.1145 - val_accuracy: 0.9798\n",
      "Epoch 174/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.1151 - val_accuracy: 0.9802\n",
      "Epoch 175/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.1203 - val_accuracy: 0.9791\n",
      "Epoch 176/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.1213 - val_accuracy: 0.9781\n",
      "Epoch 177/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.1164 - val_accuracy: 0.9783\n",
      "Epoch 178/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.1140 - val_accuracy: 0.9795\n",
      "Epoch 179/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.1157 - val_accuracy: 0.9787\n",
      "Epoch 180/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.1180 - val_accuracy: 0.9797\n",
      "Epoch 181/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9785\n",
      "Epoch 182/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.1097 - val_accuracy: 0.9797\n",
      "Epoch 183/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.1216 - val_accuracy: 0.9787\n",
      "Epoch 184/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1114 - val_accuracy: 0.9798\n",
      "Epoch 185/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.1233 - val_accuracy: 0.9780\n",
      "Epoch 186/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.1180 - val_accuracy: 0.9786\n",
      "Epoch 187/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1231 - val_accuracy: 0.9782\n",
      "Epoch 188/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1149 - val_accuracy: 0.9797\n",
      "Epoch 189/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.1149 - val_accuracy: 0.9798\n",
      "Epoch 190/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.1162 - val_accuracy: 0.9797\n",
      "Epoch 191/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1157 - val_accuracy: 0.9793\n",
      "Epoch 192/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.1151 - val_accuracy: 0.9799\n",
      "Epoch 193/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.1151 - val_accuracy: 0.9798\n",
      "Epoch 194/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.1182 - val_accuracy: 0.9789\n",
      "Epoch 195/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.1255 - val_accuracy: 0.9792\n",
      "Epoch 196/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.1233 - val_accuracy: 0.9788\n",
      "Epoch 197/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.1286 - val_accuracy: 0.9782\n",
      "Epoch 198/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.1177 - val_accuracy: 0.9793\n",
      "Epoch 199/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.1175 - val_accuracy: 0.9793\n",
      "Epoch 200/200\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.1211 - val_accuracy: 0.9794\n",
      "CPU times: user 3min 51s, sys: 22.3 s, total: 4min 13s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a2d0a20-a23c-4124-ba31-6b280cc96a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 500us/step - loss: 0.3100 - accuracy: 0.9772\n",
      "CPU times: user 307 ms, sys: 40 ms, total: 347 ms\n",
      "Wall time: 390 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "sns.lineplot(data=df[['accuracy', 'val_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca0382-41ff-4de2-876c-45a472f00c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
